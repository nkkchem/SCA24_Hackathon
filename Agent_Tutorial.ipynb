{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkkchem/SCA24_Hackathon/blob/main/Agent_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Large Language Model Agents in LangChain\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZvdvnD8EzvI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a brief introduction for how to use `LangChain` for the building of Large Language Model agents.\n",
        "\n",
        "LLM-Agents are essentially LLMs that are given tools specific to their desired task. This means that if you want an LLM to be able to configure a database, or access the internet, Agents are how you go about this task.\n",
        "\n",
        "This tutorial will step you through a potential application of LLMs - a pandas dataframe manager. We will see how to load in a local LLM through `vllm` as well as use an API-based model such as gpt-4, gemini-pro, or claude.\n",
        "\n",
        "This tutorial is adapted from a tutorial build by PineCone-IO at https://github.com/pinecone-io/examples"
      ],
      "metadata": {
        "id": "I0YFm2BlrzsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "AFllW25VtZJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start, let's install the packages we will be using for this example."
      ],
      "metadata": {
        "id": "z3pQ_JugtbMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU torch==2.3.0 vllm==0.4.2 langchain langchain_community langchain_core langchain_experimental openai google-search-results pandas langchain_openai langchain_google_genai"
      ],
      "metadata": {
        "id": "5mIAiKk45l1T"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas Agent - Setup\n",
        "\n",
        "Pretend we have an pandas dataframe (or multiple) that we would like to set up an LLM to interact with. This type of integration can provide a natural language way of gaining insights from your data. This can assist non-experts in utilizing your groups data to form insights.\n",
        "\n",
        "We will first need to create an pandas dataframe, then set up an LLM to interface with the data.\n",
        "\n",
        "⚠️ In this tutorial we will try and use local Google Colab GPU resources, but the free tier of colab prohibits larger models and may decrease the reliability of the LLM-Agents. For this situation, we will provide an additional loader for the OpenAI API models, but you will need an API-key to utilize this resoruce. ⚠️"
      ],
      "metadata": {
        "id": "h3VcwICxtf__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "rxuTdsmpvs9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Large Language Models\n",
        "\n",
        "In the following cells, we will create an LLM while pulling an example pandas dataframe from github. We will first provide instructions for spinning up a `vllm`-based LLM which pulls in models from `HuggingFace`. Then we will show the equivalent steps for OpenAI and Google.\n",
        "\n",
        "IMPORTANT: The rest of this notebook should only use one of the two approaches. Choose one of the 3 below cells to run."
      ],
      "metadata": {
        "id": "neL_6s7Svuac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CELL FOR VLLM MODELS\n",
        "\n",
        "import pandas as pd\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "from langchain_community.llms import VLLM\n",
        "\n",
        "llm = VLLM(\n",
        "    model=\"microsoft/Phi-3-mini-4k-instruct\", # Set some HF model name, we prefer smaller models since they have to fit in 15 GB of vram\n",
        "    trust_remote_code=True,  # mandatory for hf models\n",
        "    temperature=0,\n",
        "    dtype=\"float16\", # This is only required when using the T4 GPU on Colab\n",
        ")\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "JcPK5GERAJiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CELL FOR OPENAI MODELS\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0) # You need to have you OPENAI_API Key set. If not add OPENAI_API_KEY to the secrets tab on the left side of the screen (click the key)\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "fD0nkAv7xATp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CELL FOR GOOGLE MODELS\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0)\n",
        "\n",
        "df = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "SrPtadOFFtsU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "ZbGS3TPtyDk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Agent\n",
        "\n",
        "Now that we have our `llm` loaded, we can add that chain to an `AgentExecutor` type which will provide the background thought process that the agent should be able to handle.\n",
        "\n",
        "There are a few different pre-made Agent types that LangChain provides:\n",
        "\n",
        "1. Zero Shot React\n",
        "2. Conversational React\n",
        "3. React Docstore\n",
        "\n",
        "or variations of these, which can be found in the documentation [here](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_types.AgentType.html)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "We are going to use the Zero Shot React agent type. This type of agent is used to perform 'zero shot' tasks on the input. That means that we will not have several, interdependent interactions but only one. In other words, this agent will have no memory."
      ],
      "metadata": {
        "id": "Bc0dRUB2yE4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "\n",
        "agent_executor = create_pandas_dataframe_agent(\n",
        "    llm=llm,\n",
        "    df=df,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        ")"
      ],
      "metadata": {
        "id": "5Wd11tgZCYk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5925a329-e3aa-45d4-b567-0ad6c5699b25"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_experimental/agents/agent_toolkits/pandas/base.py:249: UserWarning: Received additional kwargs {'handle_parsing_errors': True} which are no longer supported.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single DataFrame\n",
        "\n",
        "Now we can run some example questions to see how well the agent handles the example dataframe."
      ],
      "metadata": {
        "id": "JE9Y296F_BoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\n",
        "    \"how many rows are there?\"\n",
        ")"
      ],
      "metadata": {
        "id": "MmKF2VFc-5On",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15d72af-d622-42ff-9362-bf309dcdca10"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I can use the `shape` attribute to get the number of rows and columns\n",
            "Action: python_repl_ast\n",
            "Action Input: df.shape\u001b[0m\u001b[36;1m\u001b[1;3m(891, 12)\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: 891\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'how many rows are there?', 'output': '891'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.run(\"how many people have more than 3 siblings\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "X2RXZo3Sg3-E",
        "outputId": "8e9bca46-2473-492a-8f9c-c72b23f3c492"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I should filter the dataframe to only include people with more than 3 siblings, then count the number of rows in the resulting dataframe\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['SibSp'] > 3].count()\u001b[0m\u001b[36;1m\u001b[1;3mPassengerId    30\n",
            "Survived       30\n",
            "Pclass         30\n",
            "Name           30\n",
            "Sex            30\n",
            "Age            23\n",
            "SibSp          30\n",
            "Parch          30\n",
            "Ticket         30\n",
            "Fare           30\n",
            "Cabin           0\n",
            "Embarked       30\n",
            "dtype: int64\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: 30\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'30'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\"whats the square root of the average age?\")"
      ],
      "metadata": {
        "id": "2Ol8vKY-hlSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8179f649-8e95-4bd2-fce6-67ac972175fd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I should first find the average age, then find the square root of that value\n",
            "Action: python_repl_ast\n",
            "Action Input: df['Age'].mean()\u001b[0m\u001b[36;1m\u001b[1;3m29.69911764705882\u001b[0m\u001b[32;1m\u001b[1;3mAction: python_repl_ast\n",
            "Action Input: (df['Age'].mean())**0.5\u001b[0m\u001b[36;1m\u001b[1;3m5.449689683556195\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: 5.449689683556195\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'whats the square root of the average age?',\n",
              " 'output': '5.449689683556195'}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple DataFrames\n",
        "\n",
        "Now that we show that we can run the LLM Agent over a single dataframe, we can add in a slightly altered version of the dataframe and show how we can pass multiple dataframes to the agent."
      ],
      "metadata": {
        "id": "r9OPc6ZW_Jq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.copy()\n",
        "df1[\"Age\"] = df1[\"Age\"].fillna(df1[\"Age\"].mean())"
      ],
      "metadata": {
        "id": "5Ux21MFP9POz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = create_pandas_dataframe_agent(\n",
        "    llm=llm,\n",
        "    df=[df,df1],\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q18p8fIW9W8p",
        "outputId": "8775e599-2311-4a2d-b476-ffece59282ec"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_experimental/agents/agent_toolkits/pandas/base.py:249: UserWarning: Received additional kwargs {'handle_parsing_errors': True} which are no longer supported.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\"Does one dataframe have more information in the age column?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PtpmNAr9cCj",
        "outputId": "59ff68a0-294e-4120-d19a-7b9da916b129"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I should check the number of non-null values in the age column of each dataframe\n",
            "Action: python_repl_ast\n",
            "Action Input: df1.age.notnull().sum()\u001b[0m\u001b[36;1m\u001b[1;3mAttributeError: 'DataFrame' object has no attribute 'age'\u001b[0m\u001b[32;1m\u001b[1;3mI should check the number of non-null values in the age column of each dataframe\n",
            "Action: python_repl_ast\n",
            "Action Input: df1['Age'].notnull().sum()\u001b[0m\u001b[36;1m\u001b[1;3m714\u001b[0m\u001b[32;1m\u001b[1;3mI should check the number of non-null values in the age column of each dataframe\n",
            "Action: python_repl_ast\n",
            "Action Input: df2['Age'].notnull().sum()\u001b[0m\u001b[36;1m\u001b[1;3m891\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: df2 has more information in the age column\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Does one dataframe have more information in the age column?',\n",
              " 'output': 'df2 has more information in the age column'}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scientific Example - Dataframe of Cells\n",
        "\n",
        "Let's look at a scientific example. We will load in a dataframe that contains information on cells. These cells are located in various tissue types and organisms. We can use this to illustrate how LLM-agents might be integrated into scientific databases.\n"
      ],
      "metadata": {
        "id": "IhzQsg4dAult"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(\"hf://datasets/pankajrajdeo/PubChem_cell/PubChem_cell_text.parquet\")"
      ],
      "metadata": {
        "id": "C9fTwNcx9gLA"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = create_pandas_dataframe_agent(\n",
        "    llm=llm,\n",
        "    df=df,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro-yYlgPBnfO",
        "outputId": "2252fe01-b33f-415a-adcc-adfd10f0f318"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_experimental/agents/agent_toolkits/pandas/base.py:249: UserWarning: Received additional kwargs {'handle_parsing_errors': True} which are no longer supported.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\"Count how many tissue types there are.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYvZuGTYDtqu",
        "outputId": "8055ed97-b95e-45ac-e709-ce85e14010a3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I should use the `nunique` function to count the number of unique values in the `tissue` column.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['tissue'].nunique()\u001b[0m\u001b[36;1m\u001b[1;3m57\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: 57\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Count how many tissue types there are.', 'output': '57'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke(\"What is the most common organism?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIezzjYODwAS",
        "outputId": "6bae7940-fe1c-45aa-af19-753403427931"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I should use the `value_counts()` function to count the number of occurrences of each organism.\n",
            "Action: python_repl_ast\n",
            "Action Input: df['organism'].value_counts()\u001b[0m\u001b[36;1m\u001b[1;3morganism\n",
            "Homo sapiens (human)                                 2403\n",
            "Cricetulus griseus (Chinese hamster)                  214\n",
            "Mus musculus (house mouse)                            207\n",
            "Rattus norvegicus (Norway rat)                         72\n",
            "Bos taurus (cattle)                                    48\n",
            "                                                     ... \n",
            "Pelodiscus sinensis (Chinese soft-shelled turtle)       1\n",
            "Gallus gallus (chicken)                                 1\n",
            "Leontocebus nigricollis (black-and-red tamarin)         1\n",
            "Tadarida brasiliensis (Brazilian free-tailed bat)       1\n",
            "Tursiops truncatus (common bottlenose dolphin)          1\n",
            "Name: count, Length: 89, dtype: int64\u001b[0m\u001b[32;1m\u001b[1;3mThe most common organism is Homo sapiens (human).\n",
            "Final Answer: Homo sapiens (human)\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the most common organism?',\n",
              " 'output': 'Homo sapiens (human)'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}